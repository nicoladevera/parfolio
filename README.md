# PARfolio

> **Turn your work experiences into interview-ready stories.**

PARfolio is an AI-powered voice-first app that helps mid-career professionals capture, structure, and organize their work experiences into interview-ready PAR (Problemâ€“Actionâ€“Result) narratives.

---

## The Problem

Mid-career professionals have valuable career stories in their heads, but those stories are messy, unstructured, and easy to forgetâ€”making interview preparation time-consuming, stressful, and inconsistent.

## The Solution

PARfolio listens to your rambling work stories, automatically structures them into a clear Problemâ€“Actionâ€“Result format, categorizes them by behavioral competency, and stores them for easy retrieval.

---

## Key Features

- ğŸ™ï¸ **Voice-First Recording**: Capture your work stories naturally through speech.
- ğŸ¤– **AI Orchestrator**: Converts rambling speech into structured PAR (Problem-Action-Result) stories.
- ğŸ§  **Personal Memory**: Upload resumes, LinkedIn data, articles, and transcripts for AI-powered semantic search and personalized coaching.
- ğŸ› ï¸ **Agentic Coaching**: AI agent autonomously retrieves user context from memory to personalize feedback.
- ğŸ·ï¸ **Behavioral Tagging**: Auto-assigns competencies like Leadership, Communication, and Impact.
- âš¡ **All-in-One Pipeline**: Orchestrate the entire flow from raw audio/text to polished PAR story in a single API call.
- ğŸ“ **Story Bank**: Manage, filter, and export your polished narratives.

---

## Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend (App)** | Flutter (Web) |
| **Marketing (Landing)** | HTML, CSS, JS (Vibrant/Playful Design) |
| **Backend** | FastAPI (Python) |
| **Database** | Firebase Firestore |
| **Auth** | Firebase Authentication |
| **Speech-to-Text** | OpenAI Whisper (Local) |
| **Vector DB** | ChromaDB (Local) |
| **AI/LLM** | Google Gemini 2.0/2.5 Pro (Primary) / OpenAI GPT-4o / Anthropic Claude 3.5 Sonnet |

---

## Project Structure

```
parfolio/
â”œâ”€â”€ frontend/                 # Flutter Web App
â”‚   â”œâ”€â”€ lib/                  # Dart source code
â”‚   â””â”€â”€ web/                  # Web entry point
â”œâ”€â”€ backend/                  # FastAPI server
â”‚   â”œâ”€â”€ main.py               # Entry point
â”‚   â”œâ”€â”€ memory/               # Personal memory logic (ChromaDB, parsing, chunking)
â”‚   â”œâ”€â”€ data/                 # Local data storage (ChromaDB persistence)
â”‚   â”œâ”€â”€ ai/                   # LangChain logic (chains, schemas, prompts) & Whisper
â”‚   â”œâ”€â”€ firebase_config.py    # Firebase initialization
â”‚   â”œâ”€â”€ firebase_storage.py   # Firebase Storage utilities
â”‚   â”œâ”€â”€ models/               # Pydantic data models
â”‚   â”œâ”€â”€ routers/              # API route handlers
â”‚   â”œâ”€â”€ dependencies/         # Auth & shared dependencies
â”‚   â”œâ”€â”€ tests/                # Verification and unit tests
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â””â”€â”€ .env.example          # Environment template
â”œâ”€â”€ marketing/                # Landing Page
â”‚   â”œâ”€â”€ index.html            # Main entry point
â”‚   â”œâ”€â”€ style.css             # Vibrant design styles
â”‚   â”œâ”€â”€ script.js             # Interactions
â”‚   â””â”€â”€ assets/               # Images and mockups
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ overview.md           # Product overview & pitch
â”‚   â”œâ”€â”€ spec_sheet.md         # Technical spec (schema, endpoints)
â”‚   â””â”€â”€ design_system.md      # Design system documentation
â””â”€â”€ README.md
```

---

## Getting Started

### Backend Setup

1. **System Dependencies**: Ensure `ffmpeg` is installed on your system (required for Whisper).
   - On Mac: `brew install ffmpeg`
   - Linux: `sudo apt install ffmpeg`

2. Navigate to the `backend` directory:
   ```bash
   cd backend
   ```

2. Set up a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   # Note: Includes ChromaDB for vector storage
   ```

4. Create a `.env` file based on `.env.example`

5. Start the server (ensure virtual environment is active):
   ```bash
   # If venv is activated (from step 2):
   uvicorn main:app --reload
   
   # Or run directly without activation:
   ./venv/bin/uvicorn main:app --reload
   ```

6. **AI Verification**: Run tests against AI and Stories endpoints:
   ```bash
   # Test AI Tagging
   python tests/test_ai_tagging.py
   
   # Test Stories CRUD (Standard pytest)
   export PYTHONPATH=$PYTHONPATH:.
   pytest tests/test_stories_unit.py
   ```

### App Setup (Flutter)

1. Navigate to the `frontend` directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   flutter pub get
   ```

3. Run the app:
   ```bash
   # For Chrome
   flutter run -d chrome
   ```

### Marketing Site Setup (Landing Page)

Simply open `marketing/index.html` in your browser. No build process required.

---

## Documentation

- [Product Overview](docs/overview.md) â€” User persona, problem, solution, and pitch
- [Technical Spec Sheet](docs/spec_sheet.md) â€” Data schema, API endpoints, and examples
- [Design System](docs/design_system.md) â€” Visual language, colors, and component specs
- [Backend AI Implementation Guide](docs/backend_ai_implementation_guide.md) â€” Strategy for building the AI pipeline
- [Frontend AI Implementation Guide](docs/frontend_ai_implementation_guide.md) â€” Phase-by-phase frontend implementation

---

## License

MIT
